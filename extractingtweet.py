# -*- coding: utf-8 -*-
"""ExtractingTweet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iSEz0mzXrtShQ4yxqVWZYMLIePl50hxv
"""

from google.colab import drive
drive.mount('/content/gdrive')

cd /content/gdrive/MyDrive/Colab Notebooks

!pip install jsonlines
!pip install twarc

# Extract Tweet data using Tweet ID
import csv
import os
import jsonlines, json
from twarc import Twarc
import twarc
import json  
print(twarc.__file__)

consumer_key=''
consumer_secret=''
access_token=''
access_token_secret=''
t = Twarc(consumer_key, consumer_secret, access_token, access_token_secret)
os.chdir("/content/gdrive/MyDrive/Colab Notebooks/PinkuPiTwitter/Twitter_ID_JNU_Clean")

input_id_file = "corona_tweets_137_Clean.csv"
input_id_file[:input_id_file.index(".")] 
output_filename = input_id_file[:input_id_file.index(".")]+".csv" 
output_json_filename = input_id_file[:input_id_file.index(".")]+ ".txt"

ids = []
with open(input_id_file, "r") as ids_file:
    ids = ids_file.read().split()
	
	
os.chdir("/content/gdrive/MyDrive/Colab Notebooks/PinkuPiTwitter/Twitter_Downloaded_Data_JNU/Everything")


hydrated_tweets = []
ids_to_hydrate = set(ids)
if os.path.isfile(output_json_filename):
    with jsonlines.open(output_json_filename, "r") as reader:
        for i in reader.iter(type=dict, skip_invalid=True):
            hydrated_tweets.append(i)
            ids_to_hydrate.remove(i["id_str"])
print("Total IDs: " + str(len(ids)) + ", IDs to hydrate: " + str(len(ids_to_hydrate)))
print("Hydrated Previously: " + str(len(hydrated_tweets)))



print("New Hydrating will start:")
count = len(hydrated_tweets)
start_index = count;
num_save  = 1000 	


for tweet in t.hydrate(ids_to_hydrate):
    hydrated_tweets.append(tweet)
    count += 1
    if (count % num_save) == 0:
        with jsonlines.open(output_json_filename, "a") as writer:
            print("Started Input-Output Operation:")
            for hydrated_tweet in hydrated_tweets[start_index:]:
                writer.write(hydrated_tweet)
            print("Finished Input-Output Operations:")
        print("Saved " + str(count) + " hydrated tweets.")
        start_index = count
        
        
if count != start_index:
    print("Here with start_index", start_index)
    with jsonlines.open(output_json_filename, "a") as writer:
        for hydrated_tweet in hydrated_tweets[start_index:]:
            writer.write(hydrated_tweet)

# Save the tweet data in text format
print("::::::Data Processing::::::::")      

                        
## 1: Fulltext with ID  
print("Processing full text::::")
Fulltest_with_ID_filename = input_id_file[:input_id_file.index(".")]+"_fulltest_id_"+".txt" 

                       
os.chdir("/content/gdrive/MyDrive/Colab Notebooks/PinkuPiTwitter/Twitter_Downloaded_Data_JNU/Fulltext")           
for item in hydrated_tweets:
    for key in item:
        if key=='id':
            # print (item[key]) 
            with open(Fulltest_with_ID_filename, "a+",encoding='utf-8') as file_object:
                 file_object.write("\n")
                 file_object.write(str(item[key])) 
                 file_object.write(" ")
                 file_object.write(":")
        if key=='full_text': 
            #     print (item[key]) 
            with open(Fulltest_with_ID_filename, "a+",encoding='utf-8') as file_object:                
                 file_object.write(item[key])
            
   

## 2: RwTweet_Count with ID
print("Processing Retweet count:::")

ReTweet_with_ID_filename = input_id_file[:input_id_file.index(".")]+"_retweet_id_"+".txt"
                         
os.chdir("/content/gdrive/MyDrive/Colab Notebooks/PinkuPiTwitter/Twitter_Downloaded_Data_JNU/ReTweetcount")           
for item in hydrated_tweets:
    for key in item:
        if key=='id':
            # print (item[key]) 
            with open(ReTweet_with_ID_filename, "a+",encoding='utf-8') as file_object:
                 file_object.write("\n")
                 file_object.write(str(item[key]))
                 file_object.write(" ")
                 file_object.write(":")
        if key=='retweet_count': 
            #     print (item[key]) 
            with open(ReTweet_with_ID_filename, "a+",encoding='utf-8') as file_object:
                 file_object.write('@retweet:')                
                 file_object.write(str(item[key]))




## 3: Hashtag with id
print("Processing Hashtag:::")
Hashtag_with_ID_filename = input_id_file[:input_id_file.index(".")]+"_hashtag_id_"+".txt"
os.chdir("/content/gdrive/MyDrive/Colab Notebooks/PinkuPiTwitter/Twitter_Downloaded_Data_JNU/Hashtag")                 
for item1 in hydrated_tweets:
    for key1 in item1:
        if key1=='id':
            with open(Hashtag_with_ID_filename, "a+",encoding='utf-8') as file_object:
                 file_object.write("\n")
                 file_object.write(str(item1[key1]))
                 file_object.write(" ")
                 file_object.write(":")
        if key1=='entities':
             dick2=item1[key1]
             for key2 in dick2: 
                 # print(key2)
                 if key2=='hashtags':
                     # print (dick2[key2])
                     listdata=dick2[key2]
                     # print(listdata)
                     with open(Hashtag_with_ID_filename, "a+",encoding='utf-8') as file_object:                         
                         file_object.write(json.dumps(listdata))                         
                         


## 4: User-->location With ID 
print("Processing user location:::")
Location_with_ID_filename = input_id_file[:input_id_file.index(".")]+"_location_id_"+".txt"

os.chdir("/content/gdrive/MyDrive/Colab Notebooks/PinkuPiTwitter/Twitter_Downloaded_Data_JNU/zUserloc");

for item1 in hydrated_tweets:
    for key1 in item1: 
        if key1=='id':
            with open(Location_with_ID_filename, "a+",encoding='utf-8') as file_object:
                 file_object.write("\n")
                 file_object.write(str(item1[key1])) 
                 file_object.write(" ")
                 file_object.write(":")
        if key1=='user':
            dick2=item1[key1]
            for key2 in dick2:
                if key2=='location':
                    listdata=dick2[key2]
                    # print(listdata)                    
                    with open(Location_with_ID_filename, "a+",encoding='utf-8') as file_object:
                         file_object.write(json.dumps(listdata))





## 5: User-->Verified With ID
print("Processing user verified:::")

os.chdir("/content/gdrive/MyDrive/Colab Notebooks/PinkuPiTwitter/Twitter_Downloaded_Data_JNU/zUserVeri")  
Verified_with_ID_filename = input_id_file[:input_id_file.index(".")]+"_verified_id_"+".txt"               
for item1 in hydrated_tweets:
    for key1 in item1: 
        if key1=='id':
            with open(Verified_with_ID_filename, "a+",encoding='utf-8') as file_object:
                 file_object.write("\n")
                 file_object.write(str(item1[key1])) 
                 file_object.write(" ")
                 file_object.write(":")                
    for key1 in item1:
         if key1=='user':
             dick2=item1[key1]
             for key2 in dick2:   
                 # print(key2)
                 if key2=='verified':
                     # print (dick2[key2]) 
                     listdata=dick2[key2]
                     # print(listdata)
                     with open(Verified_with_ID_filename, "a+",encoding='utf-8') as file_object:                         
                         file_object.write(json.dumps(listdata))



print("::::::Data Processing Completed::::::::")
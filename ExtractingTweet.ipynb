{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPP0WaNuhxFV",
        "outputId": "1ad8c944-7d03-4e85-aa2b-025d3c6fce31"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggnGDgn_iRIS",
        "outputId": "a9871a92-95a5-42fd-f2b9-de48fd112e25"
      },
      "source": [
        "cd /content/gdrive/MyDrive/Colab Notebooks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QovRqbI5ihDS",
        "outputId": "c0ec1f5b-1ae2-48f9-aabf-47d98be2a2ff"
      },
      "source": [
        "!pip install jsonlines\n",
        "!pip install twarc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading jsonlines-3.0.0-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonlines) (3.10.0.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from jsonlines) (21.2.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-3.0.0\n",
            "Collecting twarc\n",
            "  Downloading twarc-2.8.2-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting click-config-file>=0.6\n",
            "  Downloading click_config_file-0.6.0-py2.py3-none-any.whl (6.0 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=1.3 in /usr/local/lib/python3.7/dist-packages (from twarc) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8 in /usr/local/lib/python3.7/dist-packages (from twarc) (2.8.2)\n",
            "Requirement already satisfied: click<9,>=7 in /usr/local/lib/python3.7/dist-packages (from twarc) (7.1.2)\n",
            "Collecting humanize>=3.9\n",
            "  Downloading humanize-3.13.1-py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting click-plugins>=1\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: tqdm>=4.62 in /usr/local/lib/python3.7/dist-packages (from twarc) (4.62.3)\n",
            "Collecting configobj>=5.0.6\n",
            "  Downloading configobj-5.0.6.tar.gz (33 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from configobj>=5.0.6->click-config-file>=0.6->twarc) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from humanize>=3.9->twarc) (4.8.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=1.3->twarc) (3.1.1)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=1.3->twarc) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->humanize>=3.9->twarc) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->humanize>=3.9->twarc) (3.10.0.2)\n",
            "Building wheels for collected packages: configobj\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configobj: filename=configobj-5.0.6-py3-none-any.whl size=34546 sha256=b08d272a162670ec5f526dea5aa73ad13b1a98549ec8fbfe0a4fec2a2e2f3425\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/c4/19/13d74440f2a571841db6b6e0a273694327498884dafb9cf978\n",
            "Successfully built configobj\n",
            "Installing collected packages: configobj, humanize, click-plugins, click-config-file, twarc\n",
            "  Attempting uninstall: humanize\n",
            "    Found existing installation: humanize 0.5.1\n",
            "    Uninstalling humanize-0.5.1:\n",
            "      Successfully uninstalled humanize-0.5.1\n",
            "Successfully installed click-config-file-0.6.0 click-plugins-1.1.1 configobj-5.0.6 humanize-3.13.1 twarc-2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7BQ7B0ryFgR"
      },
      "source": [
        "# Extract Tweet data using Tweet ID\n",
        "import csv\n",
        "import os\n",
        "import jsonlines, json\n",
        "from twarc import Twarc\n",
        "import twarc\n",
        "import json  \n",
        "print(twarc.__file__)\n",
        "\n",
        "consumer_key=''\n",
        "consumer_secret=''\n",
        "access_token=''\n",
        "access_token_secret=''\n",
        "t = Twarc(consumer_key, consumer_secret, access_token, access_token_secret)\n",
        "os.chdir(\"/content/gdrive/MyDrive/Colab Notebooks/PinkuPiTwitter/Twitter_ID_JNU_Clean\")\n",
        "\n",
        "input_id_file = \"corona_tweets_137_Clean.csv\"\n",
        "input_id_file[:input_id_file.index(\".\")] \n",
        "output_filename = input_id_file[:input_id_file.index(\".\")]+\".csv\" \n",
        "output_json_filename = input_id_file[:input_id_file.index(\".\")]+ \".txt\"\n",
        "\n",
        "ids = []\n",
        "with open(input_id_file, \"r\") as ids_file:\n",
        "    ids = ids_file.read().split()\n",
        "\t\n",
        "\t\n",
        "os.chdir(\"/content/gdrive/MyDrive/Colab Notebooks/PinkuPiTwitter/Twitter_Downloaded_Data_JNU/Everything\")\n",
        "\n",
        "\n",
        "hydrated_tweets = []\n",
        "ids_to_hydrate = set(ids)\n",
        "if os.path.isfile(output_json_filename):\n",
        "    with jsonlines.open(output_json_filename, \"r\") as reader:\n",
        "        for i in reader.iter(type=dict, skip_invalid=True):\n",
        "            hydrated_tweets.append(i)\n",
        "            ids_to_hydrate.remove(i[\"id_str\"])\n",
        "print(\"Total IDs: \" + str(len(ids)) + \", IDs to hydrate: \" + str(len(ids_to_hydrate)))\n",
        "print(\"Hydrated Previously: \" + str(len(hydrated_tweets)))\n",
        "\n",
        "\n",
        "\n",
        "print(\"New Hydrating will start:\")\n",
        "count = len(hydrated_tweets)\n",
        "start_index = count;\n",
        "num_save  = 1000 \t\n",
        "\n",
        "\n",
        "for tweet in t.hydrate(ids_to_hydrate):\n",
        "    hydrated_tweets.append(tweet)\n",
        "    count += 1\n",
        "    if (count % num_save) == 0:\n",
        "        with jsonlines.open(output_json_filename, \"a\") as writer:\n",
        "            print(\"Started Input-Output Operation:\")\n",
        "            for hydrated_tweet in hydrated_tweets[start_index:]:\n",
        "                writer.write(hydrated_tweet)\n",
        "            print(\"Finished Input-Output Operations:\")\n",
        "        print(\"Saved \" + str(count) + \" hydrated tweets.\")\n",
        "        start_index = count\n",
        "        \n",
        "        \n",
        "if count != start_index:\n",
        "    print(\"Here with start_index\", start_index)\n",
        "    with jsonlines.open(output_json_filename, \"a\") as writer:\n",
        "        for hydrated_tweet in hydrated_tweets[start_index:]:\n",
        "            writer.write(hydrated_tweet) \n",
        "           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Sa-hNmxQzJwJ"
      },
      "source": [
        "# Save the tweet data in text format\n",
        "print(\"::::::Data Processing::::::::\")      \n",
        "\n",
        "                        \n",
        "## 1: Fulltext with ID  \n",
        "print(\"Processing full text::::\")\n",
        "Fulltest_with_ID_filename = input_id_file[:input_id_file.index(\".\")]+\"_fulltest_id_\"+\".txt\" \n",
        "\n",
        "                       \n",
        "os.chdir(\"/content/gdrive/MyDrive/Colab Notebooks/PinkuPiTwitter/Twitter_Downloaded_Data_JNU/Fulltext\")           \n",
        "for item in hydrated_tweets:\n",
        "    for key in item:\n",
        "        if key=='id':\n",
        "            # print (item[key]) \n",
        "            with open(Fulltest_with_ID_filename, \"a+\",encoding='utf-8') as file_object:\n",
        "                 file_object.write(\"\\n\")\n",
        "                 file_object.write(str(item[key])) \n",
        "                 file_object.write(\" \")\n",
        "                 file_object.write(\":\")\n",
        "        if key=='full_text': \n",
        "            #     print (item[key]) \n",
        "            with open(Fulltest_with_ID_filename, \"a+\",encoding='utf-8') as file_object:                \n",
        "                 file_object.write(item[key])\n",
        "            \n",
        "   \n",
        "\n",
        "## 2: RwTweet_Count with ID\n",
        "print(\"Processing Retweet count:::\")\n",
        "\n",
        "ReTweet_with_ID_filename = input_id_file[:input_id_file.index(\".\")]+\"_retweet_id_\"+\".txt\"\n",
        "                         \n",
        "os.chdir(\"/content/gdrive/MyDrive/Colab Notebooks/PinkuPiTwitter/Twitter_Downloaded_Data_JNU/ReTweetcount\")           \n",
        "for item in hydrated_tweets:\n",
        "    for key in item:\n",
        "        if key=='id':\n",
        "            # print (item[key]) \n",
        "            with open(ReTweet_with_ID_filename, \"a+\",encoding='utf-8') as file_object:\n",
        "                 file_object.write(\"\\n\")\n",
        "                 file_object.write(str(item[key]))\n",
        "                 file_object.write(\" \")\n",
        "                 file_object.write(\":\")\n",
        "        if key=='retweet_count': \n",
        "            #     print (item[key]) \n",
        "            with open(ReTweet_with_ID_filename, \"a+\",encoding='utf-8') as file_object:\n",
        "                 file_object.write('@retweet:')                \n",
        "                 file_object.write(str(item[key]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## 3: Hashtag with id\n",
        "print(\"Processing Hashtag:::\")\n",
        "Hashtag_with_ID_filename = input_id_file[:input_id_file.index(\".\")]+\"_hashtag_id_\"+\".txt\"\n",
        "os.chdir(\"/content/gdrive/MyDrive/Colab Notebooks/PinkuPiTwitter/Twitter_Downloaded_Data_JNU/Hashtag\")                 \n",
        "for item1 in hydrated_tweets:\n",
        "    for key1 in item1:\n",
        "        if key1=='id':\n",
        "            with open(Hashtag_with_ID_filename, \"a+\",encoding='utf-8') as file_object:\n",
        "                 file_object.write(\"\\n\")\n",
        "                 file_object.write(str(item1[key1]))\n",
        "                 file_object.write(\" \")\n",
        "                 file_object.write(\":\")\n",
        "        if key1=='entities':\n",
        "             dick2=item1[key1]\n",
        "             for key2 in dick2: \n",
        "                 # print(key2)\n",
        "                 if key2=='hashtags':\n",
        "                     # print (dick2[key2])\n",
        "                     listdata=dick2[key2]\n",
        "                     # print(listdata)\n",
        "                     with open(Hashtag_with_ID_filename, \"a+\",encoding='utf-8') as file_object:                         \n",
        "                         file_object.write(json.dumps(listdata))                         \n",
        "                         \n",
        "\n",
        "\n",
        "## 4: User-->location With ID \n",
        "print(\"Processing user location:::\")\n",
        "Location_with_ID_filename = input_id_file[:input_id_file.index(\".\")]+\"_location_id_\"+\".txt\"\n",
        "\n",
        "os.chdir(\"/content/gdrive/MyDrive/Colab Notebooks/PinkuPiTwitter/Twitter_Downloaded_Data_JNU/zUserloc\");\n",
        "\n",
        "for item1 in hydrated_tweets:\n",
        "    for key1 in item1: \n",
        "        if key1=='id':\n",
        "            with open(Location_with_ID_filename, \"a+\",encoding='utf-8') as file_object:\n",
        "                 file_object.write(\"\\n\")\n",
        "                 file_object.write(str(item1[key1])) \n",
        "                 file_object.write(\" \")\n",
        "                 file_object.write(\":\")\n",
        "        if key1=='user':\n",
        "            dick2=item1[key1]\n",
        "            for key2 in dick2:\n",
        "                if key2=='location':\n",
        "                    listdata=dick2[key2]\n",
        "                    # print(listdata)                    \n",
        "                    with open(Location_with_ID_filename, \"a+\",encoding='utf-8') as file_object:\n",
        "                         file_object.write(json.dumps(listdata))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## 5: User-->Verified With ID\n",
        "print(\"Processing user verified:::\")\n",
        "\n",
        "os.chdir(\"/content/gdrive/MyDrive/Colab Notebooks/PinkuPiTwitter/Twitter_Downloaded_Data_JNU/zUserVeri\")  \n",
        "Verified_with_ID_filename = input_id_file[:input_id_file.index(\".\")]+\"_verified_id_\"+\".txt\"               \n",
        "for item1 in hydrated_tweets:\n",
        "    for key1 in item1: \n",
        "        if key1=='id':\n",
        "            with open(Verified_with_ID_filename, \"a+\",encoding='utf-8') as file_object:\n",
        "                 file_object.write(\"\\n\")\n",
        "                 file_object.write(str(item1[key1])) \n",
        "                 file_object.write(\" \")\n",
        "                 file_object.write(\":\")                \n",
        "    for key1 in item1:\n",
        "         if key1=='user':\n",
        "             dick2=item1[key1]\n",
        "             for key2 in dick2:   \n",
        "                 # print(key2)\n",
        "                 if key2=='verified':\n",
        "                     # print (dick2[key2]) \n",
        "                     listdata=dick2[key2]\n",
        "                     # print(listdata)\n",
        "                     with open(Verified_with_ID_filename, \"a+\",encoding='utf-8') as file_object:                         \n",
        "                         file_object.write(json.dumps(listdata))\n",
        "\n",
        "\n",
        "\n",
        "print(\"::::::Data Processing Completed::::::::\") \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}